# Physical Nodes
I'm going to start with a single node install on a server at home and then, slowly, add additional nodes to create a cluster. I'll `taint` the first node though so that it can run standalone without needing further nodes to operate.

My final configuration will look roughly like this:

* Homelab
    * Server 1: Dell R610, Primary Compute, `asimov`
    * Server 2: Dell R710, Secondary Compute, `banks`
    * Server 3: Custom Build, Primary LAN Storage, `clarke`
* Cloud
    * Dedicated Server 1: Kimsufi, Ingress Node, `donaldson`

Between the `Homelab` and `Cloud` I'll run a VPN such that traffic is encrypted and we can bypass the public internet and any associated NAT / routing issues by having the nodes discover each other using VPN subnet addresses.

## Banks
### Basic housekeeping
First of all install the latest Ubuntu 18.04 LTS release and copy across your ssh key and then follow some simple hardening steps `#TODO: link to ansible`.

### Setup Wireguard (VPN)
See [Wireguard vs OpenVPN on a local Gigabit Network](https://snikt.net/blog/2018/12/13/wireguard-vs-openvpn-on-a-local-gigabit-network/) for a performance comparison. I've gone with Wireguard over OpenVPN based on it being incorporated into the Linux Kernel and increased performance versus OpenVPN.

#### Install Wireguard
```bash
add-apt-repository -y ppa:wireguard/wireguard
apt-get install -y wireguard
modprobe wireguard  # activate kernal module
```

???+ check "Check Kernel Module"
    To check if the module is loaded use `lsmod | grep wireguard`. You should see something like the below.

    ```bash
    root@banks:~# lsmod | grep wireguard
    wireguard             212992  0
    ip6_udp_tunnel         16384  1 wireguard
    udp_tunnel             16384  1 wireguard
    ```

#### Keys
You will need to generate a key-pair for every peer (device) that is connected, including things like mobile phones etc. The iOS WireGuard client allow you to generate the keys on the device itself (if you want).

```bash
# Generate public/private keypair
cd /etc/wireguard
umask 077
wg genkey | sudo tee privatekey | wg pubkey | sudo tee publickey
```

#### Configure
We need to create a network interface now for the wireguard VPN. Common convention is to use `wg0` as a name for this. In addition we also need to choose a `subnet` for the VPN addresses. As I've got a `192.168.0.1/24` configuration at home I'll use `10.10.0.1/24` for the VPN.

Note the highlighted IP address we assign to each node here. It will need to be incremented for each to provide a unique address.

```bash hl_lines="4 5"
# file: /etc/wireguard/wg0.conf
[Interface]
PrivateKey = {{PRIVATE_KEY}}
Address = 10.10.0.1/24
Address = fd86:ea04:1111::1/64
SaveConfig = true
PostUp = iptables -A FORWARD -i wg0 -j ACCEPT; iptables -t nat -A POSTROUTING -o {{ETH0}} -j MASQUERADE; ip6tables -A FORWARD -i wg0 -j ACCEPT; ip6tables -t nat -A POSTROUTING -o {{ETH0}} -j MASQUERADE
PostDown = iptables -D FORWARD -i wg0 -j ACCEPT; iptables -t nat -D POSTROUTING -o {{ETH0}} -j MASQUERADE; ip6tables -D FORWARD -i wg0 -j ACCEPT; ip6tables -t nat -D POSTROUTING -o {{ETH0}} -j MASQUERADE
ListenPort = 51820
```

Now to keepo things DRY we'll run the following to replace the placeholder text with the actual contents of our server's private key we generated earlier. 

```bash
sed -i.bak 's/{{PRIVATE_KEY}}/'$(cat /etc/wireguard/privatekey)'/' /etc/wireguard/wg0.conf
```

We also need to replace the `{{ETH0}}` placeholder with the name of our existing primary network interface. A quick one-liner for this is `ip -4 route | grep default | awk '{print $5}'` which, on my server, gives `bond0` as the answer (as I'm running LACP across multiple bonded physical interfaces).

```bash
sed -i.bak 's/{{ETH0}}/'$(ip -4 route | grep default | awk '{print $5}')'/'  /etc/wireguard/wg0.conf
```

Enable forwarding of packets in the host kernel.


```bash
cat << EOF >> /etc/sysctl.conf
net.ipv4.ip_forward=1
net.ipv6.conf.all.forwarding=1
EOF
sysctl -p
```

Finally we can start the `wg0` interface.

```bash
wg-quick up wg0
```

Hopefully you'll see something like the below output.

```bash
root@banks:/etc/wireguard# wg-quick up wg0
[#] ip link add wg0 type wireguard
[#] wg setconf wg0 /dev/fd/63
[#] ip -4 address add 10.10.0.1/24 dev wg0
[#] ip -6 address add fd86:ea04:1111::1/64 dev wg0
[#] ip link set mtu 1420 up dev wg0
[#] iptables -A FORWARD -i wg0 -j ACCEPT; iptables -t nat -A POSTROUTING -o bond0 -j MASQUERADE; ip6tables -A FORWARD -i wg0 -j ACCEPT; ip6tables -t nat -A POSTROUTING -o {{ETH0}} -j MASQUERADE
```

??? check "Checking status"
    The check the status of wireguard run the `wg` command.

    ```bash
    root@banks:/etc/wireguard# wg
    interface: wg0
        public key: I6ZHsLe44SHNH44xE86AI0VEnm8CfzrQUrxSCJVjAEw=
        private key: (hidden)
        listening port: 51820
    ```

    In addition, we should now have an additional `route` appear for our VPN subnet.

    ```bash hl_lines="3"
    root@banks:/etc/wireguard# ip route
    default via 192.168.0.1 dev bond0 proto dhcp src 192.168.0.94 metric 100 
    10.10.0.0/24 dev wg0 proto kernel scope link src 10.10.0.1 
    172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1 linkdown 
    ...
    ```

### Install Kubernetes
#### Docker
As Kubernetes is an orchestration layer we will need to install a container runtime eninge. The below commands will install a compatible version of Docker.

???+ info "Kubernetes and Docker versions"
    It's worth being aware that Kubernetes only supports specific versions of docker and, as a result, you should check for compatability in their changelog. At time of writing the latest stable version of Kubernetes was 1.16. The [CHANGELOG-1.16](https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG-1.16.md#dependencies) shows that they have `validated` the following docker versions:

    >* The list of validated docker versions remains unchanged.
    >* The current list is 1.13.1, 17.03, 17.06, 17.09, 18.06, 18.09

```bash
K8S_DOCKER_VERSION=18.09
apt-get update
apt-get install -y \
    apt-transport-https \
    ca-certificates \
    curl \
    software-properties-common
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | apt-key add -
add-apt-repository \
   "deb https://download.docker.com/linux/$(. /etc/os-release; echo "$ID") \
   $(lsb_release -cs) \
   stable"
apt-get update && apt-get install -y docker-ce=$(apt-cache madison docker-ce | grep ${K8S_DOCKER_VERSION} | head -1 | awk '{print $3}')
```

#### Kubernetes
With docker now setup as a runtime we'll install Kubernetes.

```bash
apt-get update && apt-get install -y apt-transport-https
curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -
cat <<EOF >/etc/apt/sources.list.d/kubernetes.list
deb http://apt.kubernetes.io/ kubernetes-xenial main
EOF
apt-get update
apt-get install -y kubelet kubeadm kubectl
```

Initialise the node with Canal as a CNI (networking solution between pods). We'll use our [VPN address](#setup-wireguard-vpn) here as the address to listen on.



### Enable Avahi (Discovery) on VPN and LAN
As per [Wikipedia](https://en.wikipedia.org/wiki/Avahi_%28software%29).

>Avahi is a free zero-configuration networking (zeroconf) implementation, including a system for multicast DNS/DNS-SD service discovery. It is licensed under the GNU Lesser General Public License (LGPL).
>
>Avahi is a system which enables programs to publish and discover services and hosts running on a local network. For example, a user can plug a computer into a network and have Avahi automatically advertise the network services running on its machine, facilitating user access to those services.

We will setup our nodes to publish themselves on both the LAN (so can be accessed via their hostnames) and VPN.

```bash
export DEBIAN_FRONTEND=noninteractive  # from docker
apt-get update -y
apt-get -qq install -y avahi-daemon avahi-utils
```

The main configuration is held in `/etc/avahi/avahi-daemon.conf`. We want to modify the following line (to limit which interfaces we advertise on).

This will be useful for when we want to only enable it on *internal* interfaces (e.g. our Cloud node shouldn't try and broadcast across the in)

```bash
#file: /etc/avahi/avahi-daemon.conf
allow-interfaces=bond0, wg0, docker0
```